{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from callbacks import EpochCallback\n",
    "from experiment import Experiment\n",
    "from training import TrainSetup, setup_training\n",
    "\n",
    "def mycallback(D: dict, TS: TrainSetup):\n",
    "    print(\"Running callback.\")\n",
    "    pass\n",
    "\n",
    "def my_setup_training():\n",
    "    return TrainSetup(\n",
    "        model=None, \n",
    "        dataloader=None,\n",
    "        optimizer=None,\n",
    "        objective=None,\n",
    "        num_epochs=None)\n",
    "\n",
    "mydict = {}\n",
    "\n",
    "epoch_callback = EpochCallback([mycallback], mydict)\n",
    "experiment = Experiment(my_setup_training, epoch_callback)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "\n",
    "class MLP(nn.Module):\n",
    "  def __init__(self,  activation=nn.ReLU, in_size=2, out_size=1, hidden_size=3, hidden_width=256):\n",
    "    super(MLP, self).__init__()\n",
    "\n",
    "    layers = []\n",
    "    layers.append(nn.Linear(in_size, hidden_width))\n",
    "    layers.append(activation())\n",
    "\n",
    "    for _ in range(hidden_size):\n",
    "      layers.append(nn.Linear(hidden_width, hidden_width))\n",
    "      layers.append(activation())\n",
    "\n",
    "    layers.append(nn.Linear(hidden_width, out_size))\n",
    "    self.layers = nn.Sequential(*layers)\n",
    "\n",
    "  def forward(self, x):\n",
    "    return self.layers(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'MSELoss' object has no attribute 'backwards'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m/Users/jakubszymkowiak/Documents/Work/mlp-lib/test.ipynb Cell 3\u001b[0m line \u001b[0;36m3\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/jakubszymkowiak/Documents/Work/mlp-lib/test.ipynb#W1sZmlsZQ%3D%3D?line=22'>23</a>\u001b[0m experiment \u001b[39m=\u001b[39m Experiment(setup_training, epoch_callback)\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/jakubszymkowiak/Documents/Work/mlp-lib/test.ipynb#W1sZmlsZQ%3D%3D?line=23'>24</a>\u001b[0m experiment\u001b[39m.\u001b[39msetup(\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/jakubszymkowiak/Documents/Work/mlp-lib/test.ipynb#W1sZmlsZQ%3D%3D?line=24'>25</a>\u001b[0m     model\u001b[39m=\u001b[39mmodel,\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/jakubszymkowiak/Documents/Work/mlp-lib/test.ipynb#W1sZmlsZQ%3D%3D?line=25'>26</a>\u001b[0m     \u001b[39minput\u001b[39m\u001b[39m=\u001b[39m\u001b[39minput\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/jakubszymkowiak/Documents/Work/mlp-lib/test.ipynb#W1sZmlsZQ%3D%3D?line=30'>31</a>\u001b[0m     learning_rate\u001b[39m=\u001b[39mlearning_rate,\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/jakubszymkowiak/Documents/Work/mlp-lib/test.ipynb#W1sZmlsZQ%3D%3D?line=31'>32</a>\u001b[0m     batch_size\u001b[39m=\u001b[39mbatch_size)\n\u001b[0;32m---> <a href='vscode-notebook-cell:/Users/jakubszymkowiak/Documents/Work/mlp-lib/test.ipynb#W1sZmlsZQ%3D%3D?line=33'>34</a>\u001b[0m experiment\u001b[39m.\u001b[39;49mrun()\n",
      "File \u001b[0;32m~/Documents/Work/mlp-lib/experiment.py:20\u001b[0m, in \u001b[0;36mExperiment.run\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mrun\u001b[39m(\u001b[39mself\u001b[39m):\n\u001b[0;32m---> 20\u001b[0m     \u001b[39mreturn\u001b[39;00m train(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtrain_setup, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mepoch_callback)\n",
      "File \u001b[0;32m~/Documents/Work/mlp-lib/training.py:39\u001b[0m, in \u001b[0;36mtrain\u001b[0;34m(train_setup, epoch_callback)\u001b[0m\n\u001b[1;32m     37\u001b[0m     output \u001b[39m=\u001b[39m train_setup\u001b[39m.\u001b[39mmodel(batch_x)\n\u001b[1;32m     38\u001b[0m     loss \u001b[39m=\u001b[39m train_setup\u001b[39m.\u001b[39mobjective(output, batch_y)\n\u001b[0;32m---> 39\u001b[0m     train_setup\u001b[39m.\u001b[39;49mobjective\u001b[39m.\u001b[39;49mbackwards()\n\u001b[1;32m     40\u001b[0m     train_setup\u001b[39m.\u001b[39moptimizer\u001b[39m.\u001b[39mstep()\n\u001b[1;32m     41\u001b[0m epoch_callback(train_setup)\n",
      "File \u001b[0;32m/opt/homebrew/Caskroom/miniconda/base/envs/mainenv/lib/python3.11/site-packages/torch/nn/modules/module.py:1695\u001b[0m, in \u001b[0;36mModule.__getattr__\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m   1693\u001b[0m     \u001b[39mif\u001b[39;00m name \u001b[39min\u001b[39;00m modules:\n\u001b[1;32m   1694\u001b[0m         \u001b[39mreturn\u001b[39;00m modules[name]\n\u001b[0;32m-> 1695\u001b[0m \u001b[39mraise\u001b[39;00m \u001b[39mAttributeError\u001b[39;00m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m'\u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mtype\u001b[39m(\u001b[39mself\u001b[39m)\u001b[39m.\u001b[39m\u001b[39m__name__\u001b[39m\u001b[39m}\u001b[39;00m\u001b[39m'\u001b[39m\u001b[39m object has no attribute \u001b[39m\u001b[39m'\u001b[39m\u001b[39m{\u001b[39;00mname\u001b[39m}\u001b[39;00m\u001b[39m'\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'MSELoss' object has no attribute 'backwards'"
     ]
    }
   ],
   "source": [
    "from torch.nn import Linear\n",
    "from torch import Tensor\n",
    "\n",
    "from torch.optim import Adam\n",
    "from torch.nn import MSELoss\n",
    "\n",
    "import torch\n",
    "\n",
    "def message_callback(config: dict) -> None:\n",
    "    print(\"Message callback.\")\n",
    "\n",
    "epoch_callback = EpochCallback([message_callback], {\"x\": 1})\n",
    "\n",
    "model = MLP(in_size=5, out_size=1)\n",
    "input = torch.rand(5,5)\n",
    "target = Tensor([1,2,3,4,5])\n",
    "objective = MSELoss()\n",
    "optimization = Adam\n",
    "num_epochs = 5\n",
    "learning_rate = 0.1\n",
    "batch_size = 2\n",
    "\n",
    "experiment = Experiment(setup_training, epoch_callback)\n",
    "experiment.setup(\n",
    "    model=model,\n",
    "    input=input,\n",
    "    target=target,\n",
    "    objective=objective,\n",
    "    optimization=optimization,\n",
    "    num_epochs=num_epochs,\n",
    "    learning_rate=learning_rate,\n",
    "    batch_size=batch_size)\n",
    "\n",
    "experiment.run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "isinstance(model, torch.nn.Module)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
